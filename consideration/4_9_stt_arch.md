# 🎧 Whisper 기반 실시간 오디오 스트리밍 처리 시스템 설계 문서

## ✅ 개요
본 문서는 Whisper 모델을 활용하여 웹소켓 없이 실시간으로 오디오를 받아 텍스트로 변환하는 시스템 설계 내용을 정리한 것입니다.
이 구조는 브라우저 외 환경(디스코드, 스카이프 등)에서도 음성 데이터를 직접 전달받아 사용할 수 있도록 설계되었습니다.

## 🧠 핵심 설계 요약

1. Whisper 모델은 실행 시 메모리에 상주하며, 반복적으로 호출 가능한 상태로 유지된다.
2. 오디오 입력을 실시간으로 받아 버퍼에 저장하는 별도의 입력 처리 프로그램이 필요하다.
3. 해당 입력 처리 프로그램은 pseudo-streaming 원칙(청크 분리 + 프리픽스 사용)을 따르며 **기존 stt 컨테이너에 청크 데이터를 전송**한다.
4. Whisper는 오디오 입력이 2초 이상 멈추면 문장이 끝난 것으로 간주하고 텍스트 출력을 반환한다.
5. Whisper는 해당 청크에 대한 전체 텍스트 출력을 반환한다.

## 🎯 실현 전략 및 컨테이너 역할 분리

- `stt/`: Whisper 모델을 포함하고, `/transcribe-chunk` 같은 새로운 엔드포인트를 통해 외부에서 전송되는 오디오 청크를 처리한다.
- `hub_server/`: STT/TTS/LLM 등 모든 입력-출력 흐름을 조율하는 중재자 역할. 이번 경우엔 마이크 입력 → STT로 전달하는 로직을 포함한다.
- `hub_server/audio_streaming_input/`: 실시간 마이크 또는 오디오 스트림을 수신하고, pseudo-streaming 방식으로 청크를 생성하여 `stt`에 전송한다.

## 📁 디렉토리 구조 예상

```
ai-vtuber-project/
├── stt/
│   ├── app.py                # FastAPI 서버 (transcribe, transcribe-chunk 등 포함)
│   ├── utils/
│   │   └── transcriber.py    # Whisper 모델 관리 및 텍스트 변환
├── hub_server/
│   └── audio_streaming_input/
│       ├── mic_capture.py         # 실시간 오디오 캡처
│       ├── stream_buffer.py       # 청크 & 프리픽스 버퍼 관리
│       └── stt_sender.py          # STT 컨테이너로 청크 전송
```

## 📌 추가 고려 사항

- Whisper 서버는 단일 인스턴스로 운영하며, 멀티유저 환경에서는 세션별 버퍼 구조 필요
- Whisper 추론 중 타임아웃/중복 발생 대비해 Prefix 처리 및 중복 제거 로직 구현 필요
- 오디오 입력은 멀티 소스에서 받아들일 수 있도록 추상화 인터페이스 고려
- STT 외 TTS/LLM/유니티 연동을 위한 WebSocket, gRPC, REST API 연계 구조 적용 고려

## ✅ 검토 및 정리

✔️ 전체 흐름 및 구조는 Whisper 특성에 맞게 잘 설계됨  
✔️ 실시간 입력, 청크 분리, 모델 연결 구조가 명확함  
✔️ 디렉토리 구분 및 확장 구조도 깔끔하게 나눠짐

## 🔧 향후 확장 시 고려할 점

- 마이크 입력 외에도 시스템 오디오 입력(예: 가상 오디오 인터페이스) 연동
- Whisper를 대신할 수 있는 경량 모델 연동 옵션 고려
- Whisper의 동시 처리 제한을 넘기 위한 비동기 큐 또는 모델 풀 도입
- TTS/LLM/유니티 연동을 위한 중앙 통신 모듈(Hub Server) 확장 설계

---
> 본 문서는 Whisper 실시간 입력 기반 STT 시스템을 기초로, 음성 기반 멀티모달 AI 시스템 개발을 위한 확장 가능 설계를 목표로 작성되었습니다.
