# 🗣️ TTS (Text-to-Speech) 성능 향상을 위한 고려사항

AI Vtuber 시스템의 몰입도는 음성 합성 품질에 큰 영향을 받습니다.  
특히 "페르소나의 유지", "감정 표현", "입모양 동기화"와 같은 요소들은 단순 음성 생성 이상의 품질을 요구합니다.

다음은 TTS 성능을 향상시키기 위한 주요 고려사항입니다:

---

## 1. 🔊 고품질 TTS 모델 선택

### ✔️ 고려 기술
- **VITS / Tacotron2 / FastSpeech2**
- **GPT-SoVITS** → (최신 구조, GPT 계열과 연동 용이)

### ✔️ 이유 및 기대
- GPT-SoVITS는 **자연스러운 발음 + 감정 기반 말투** 구현이 가능함.
- Text 조건과 Speaker Embedding, Pitch Embedding이 동시에 반영됨.
- 페르소나 일관성을 높이기 위해 다양한 감정 발화를 표현하는 데 매우 유리함.

> 기대 성능 향상: 더 자연스럽고 사람 같은 말투 구현 가능 → 사용자 몰입도 증가

---

## 2. 🎭 감정 표현(Emotion Conditioning) 지원

### ✔️ 적용 방안
- 감정 태그 추가: `happy`, `angry`, `sad` 등
- 감정별 음성 데이터로 클러스터링된 학습

### ✔️ 이유 및 기대
- 동일한 문장도 상황에 따라 다른 톤이 필요함.
- 사용자의 질문 감정에 맞춰 맞춤 음성으로 응답 가능

> 기대 성능 향상: **페르소나 몰입도 및 자연스러움 향상**, 스트리밍/방송 AI로 적합

---

## 3. 🎙️ 음성 데이터 전처리 및 정규화

### ✔️ 적용 항목
- 음성 클리핑 제거
- 노이즈 제거
- 음량 정규화 (-20 dBFS 정도로)
- Sample rate 일관성 (22kHz 또는 24kHz 권장)

### ✔️ 이유 및 기대
- 학습/추론에 사용되는 음성이 일관되지 않으면 품질 저하
- 입모양 동기화(유니티) 정확도에도 직접적 영향

> 기대 성능 향상: **보다 정돈된 합성 음성 품질 확보**, 딕션 향상

---

## 4. 🧠 Speaker Embedding 정교화

### ✔️ 적용 방안
- 고정된 목소리 스타일 벡터 사용
- 동일 화자 데이터를 기반으로 클러스터링/분리

### ✔️ 이유 및 기대
- 다양한 문장에서도 동일 화자처럼 들리는 일관된 목소리 보장
- 다중 화자 구분도 가능

> 기대 성능 향상: **페르소나 유지력 증가**, 복수 캐릭터 대응 가능

---

## 5. 🎵 Pitch & Speed Control (음높이/속도 제어)

### ✔️ 적용 방식
- API 요청에 pitch, speed 파라미터 포함
- 감정 변화에 따라 pitch 조절 자동화

### ✔️ 이유 및 기대
- 같은 문장도 속도/톤에 따라 완전히 다른 느낌
- 감정 연출, 상황 맥락 전달 효과 극대화

> 기대 성능 향상: **실제 사람과 비슷한 말하기 스타일 생성**

---

## 6. 🧪 모델 추론 최적화 (실시간성 향상)

### ✔️ 고려 기술
- ONNX로 모델 최적화
- half-precision(float16) 추론
- GPU 사용 (CUDA 가속)

### ✔️ 이유 및 기대
- 실시간 대화 시스템이기 때문에 latency는 핵심 요소
- Whisper + TTS 연동 시 자연스러운 흐름 유지 필수

> 기대 성능 향상: **응답 지연 최소화**, 사용자의 몰입감 유지

---

## 7. 🤖 LLM 연동 기반 말투 조정

### ✔️ 적용 방법
- LLM(GPT)에서 감정 및 어조 태그 생성 → TTS에 전달
- 예: “오늘 기분 어때요?” → `{text: ..., emotion: happy, pitch: +2}`

### ✔️ 이유 및 기대
- 대화 내용 기반 자동 감정 연출
- 사용자의 의도에 맞는 응답 분위기 조절 가능

> 기대 성능 향상: **맥락 이해 + 어조 표현의 시너지 극대화**

---

## ✅ 종합 기대 효과

| 향상 요소          | 기대 효과 |
|-------------------|-----------|
| 음질 향상         | 더 깨끗하고 자연스러운 음성 출력 |
| 페르소나 일관성   | AI 캐릭터 몰입도 증가 |
| 감정 표현         | 상황별 맞춤 반응 제공 가능 |
| 립싱크 정확도     | 애니메이션 연동 정밀도 향상 |
| 반응 속도 개선    | 실시간 대화 시스템에서 자연스러운 흐름 유지 |

---

> 💡 이 고려사항들을 단계적으로 반영하면 단순한 음성 합성을 넘어,  
> 실제 사람처럼 반응하고 감정을 전달할 수 있는 **AI 캐릭터 음성 시스템**으로 발전할 수 있습니다.
