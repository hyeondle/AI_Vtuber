# stt/cpu_ws/utils/transcriber.py

import whisper
import tempfile

# ëª¨ë¸ ìºì‹œ
MODEL_CACHE = {}

def load_model(device="cpu"):
    """ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ (ì´ë¯¸ ë¡œë“œëœ ê²½ìš° íŒ¨ìŠ¤)"""
    if device not in MODEL_CACHE:
        MODEL_CACHE[device] = whisper.load_model("base", device=device)
    return MODEL_CACHE[device]

def transcribe_from_bytes(audio_bytes: bytes, prompt: str = "", device: str = "cpu") -> str:
    """ë°”ì´íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ ì…ë ¥ì„ ë°›ì•„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    model = MODEL_CACHE.get(device)
    if not model:
        raise RuntimeError(f"ğŸ”´ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: device={device}")

    # prefix í”„ë¡¬í”„íŠ¸ ì¶”ê°€ (ì˜µì…˜)
    initial_prompt = (
        """
        If nothing detected, return empty string.\nThis is Korean speech. I'll give you chunked audio.\n
        Please use previous context if provided.\nPrompt:
        """
    ) + (prompt if prompt else "")

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp:
        tmp.write(audio_bytes)
        tmp.flush()
        result = model.transcribe(
            tmp.name,
            language="ko",
            temperature=0.0,
            best_of=5,
            beam_size=5,
        )
        return result.get("text", "").strip()
